{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_hep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_hep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlorentz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MomentumTensor\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutations, groupby, combinations\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Optional\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_hep'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import h5py\n",
    "import yaml\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_hep.lorentz import MomentumTensor\n",
    "from itertools import permutations, groupby, combinations\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "\n",
    "class EdgeEmbedding(object):\n",
    "    def __init__(self, u: MomentumTensor, v: MomentumTensor):\n",
    "        r\"\"\"Calculate edge embedding.\n",
    "\n",
    "        Input tensors should store node kinematics in EEtaPhiPt or MEtaPhiPt order.\n",
    "        Args:\n",
    "            u (torch.Tensor): input tensor with size torch.Size([N,4]).\n",
    "            v (torch.Tensor): input tensor with size torch.Size([N,4]).\n",
    "        \"\"\"\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "\n",
    "    def dEta(self):\n",
    "        return self.u.eta - self.v.eta\n",
    "\n",
    "    def dPhi(self):\n",
    "        return torch.arctan2(torch.sin(self.u.phi-self.v.phi),torch.cos(self.u.phi-self.v.phi))\n",
    "\n",
    "    def dR(self):\n",
    "        return torch.sqrt((self.dEta())**2+(self.dPhi())**2)\n",
    "\n",
    "    def M(self):\n",
    "        p4 = self.u + self.v\n",
    "        return p4.m\n",
    "    \n",
    "    def theta_p(self):\n",
    "        jcv21_rap = self.v.rapidity - self.u.rapidity\n",
    "        jcv21_phi = torch.arctan2(torch.sin(self.v.phi-self.u.phi),torch.cos(self.v.phi-self.u.phi))\n",
    "        return torch.arctan2( jcv21_rap*self.u.pull_phi - jcv21_phi*self.u.pull_rapidity, jcv21_rap*self.u.pulls_rapidity + jcv21_phi*self.u.pulls_phi)\n",
    "\n",
    "\n",
    "\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"HyPER Graph Dataset interfaced with HDF5 file format. `GraphDataset`\n",
    "    embeds data into the graph structure when required.\n",
    "\n",
    "    Args:\n",
    "        path (str): path to the dataset.\n",
    "        configs (str): a :obj:`yaml` file saves dataset configurations.\n",
    "        use_index_select (optional, bool): use :obj:`IndexSelect` provided in the :obj:`.h5`\n",
    "            file to select out graphs (default: :obj:`False`).\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, configs: str, use_index_select: Optional[bool] = False):\n",
    "        super(GraphDataset).__init__()\n",
    "\n",
    "        with open(configs, 'r') as config_file:\n",
    "            cf = yaml.safe_load(config_file)\n",
    "            assert 'INPUTS' in cf.keys(), \"Data group `INPUTS` must be provided.\"\n",
    "            assert 'LABELS' in cf.keys(), \"Data group `LABELS` must be provided.\"\n",
    "\n",
    "            assert 'Objects' in cf['INPUTS'].keys(), \"A list of `Objects` must be provided.\"\n",
    "            assert 'Features' in cf['INPUTS'].keys(), \"A list of `Features` must be provided.\"\n",
    "            assert 'global' in cf['INPUTS'].keys(), \"Event `global` must be provided.\"\n",
    "\n",
    "            self.objects = cf['INPUTS']['Objects']\n",
    "            self.node_features = list(cf['INPUTS']['Features'].keys())\n",
    "            self.node_scalings = list(cf['INPUTS']['Features'].values())\n",
    "            self.global_features = list(cf['INPUTS']['global'].keys())\n",
    "            self.global_scalings = list(cf['INPUTS']['global'].values())\n",
    "\n",
    "            self.edge_identifiers = np.apply_along_axis(\n",
    "                lambda x: 2**x, axis=0, arr=list(cf['LABELS']['Edges'].values())\n",
    "            ).sum(axis=1)\n",
    "            self.hyperedge_identifiers = np.apply_along_axis(\n",
    "                lambda x: 2**x, axis=0, arr=list(cf['LABELS']['Hyperedges'].values())\n",
    "            ).sum(axis=1)\n",
    "\n",
    "            try:\n",
    "                HE_ids = np.array(list(cf['LABELS']['Hyperedges'].values()))\n",
    "                self.hyperedge_order = HE_ids.shape[1]\n",
    "            except ValueError:\n",
    "                print(\"HyPER currently only support hyperedges with the same order.\")\n",
    "\n",
    "        self.file_path = path\n",
    "        self.use_index_select = use_index_select\n",
    "\n",
    "        with h5py.File(self.file_path, 'r') as file:\n",
    "            # Check dataset\n",
    "            assert 'INPUTS' in file.keys(), \"Data group `INPUTS` must be provided.\"\n",
    "            assert 'LABELS' in file.keys(), \"Data group `LABELS` must be provided.\"\n",
    "\n",
    "            self.inputs = list(file['INPUTS'].keys())\n",
    "            self.labels = list(file['LABELS'].keys())\n",
    "\n",
    "            assert 'VertexID' in self.labels, \"`VertexID` must be provided in the dataset.\"\n",
    "\n",
    "            assert set(self.objects).issubset(set(self.inputs)), \"One or more `Objects` provided not found in the dataset.\"\n",
    "            g = groupby([file['INPUTS'][obj].dtype.fields.keys() for obj in self.objects])\n",
    "            assert next(g, True) and not next(g, False), \"All provided node objects (`jet`, `electron` etc.) must have the same `numpy.dtype`, including the name of the features.\"\n",
    "            assert self.node_features == list(file['INPUTS'][self.objects[0]].dtype.fields.keys()), \"Defined `Features` do not match the ones found in dataset, they must also be ordered.\"\n",
    "\n",
    "            assert 'global' in self.inputs, \"`global` variables must be provided.\"\n",
    "            assert self.global_features == list(file['INPUTS']['global'].dtype.fields.keys()), \"Defined `global` variables do not match the ones found in dataset, they must also be ordered.\"\n",
    "\n",
    "            if self.node_features[:4] != ['e', 'eta', 'phi', 'pt']:\n",
    "                warnings.warn(\"You are not using the standard feature ordering or the naming scheme: ['e', 'eta', 'phi', 'pt'] (for the first 4). This might cause problem in the edge computing stage.\", UserWarning)\n",
    "\n",
    "            self.size = len(file['INPUTS'][self.objects[0]])\n",
    "\n",
    "            self.index_select = None\n",
    "            if 'IndexSelect' in file['LABELS']:\n",
    "                self.index_select = np.array(range(self.size))[np.array(file['LABELS']['IndexSelect'],dtype=np.int64)==1]\n",
    "                if self.use_index_select:\n",
    "                    self.size = len(self.index_select)\n",
    "            else:\n",
    "                if self.use_index_select:\n",
    "                    warnings.warn(\"`IndexSelect` not found in `LABELS`. No index selection will be made.\")\n",
    "                    self.use_index_select = False\n",
    "\n",
    "\n",
    "    def get_node_feats(self, inputs_db, index):\n",
    "        r\"\"\"Get node features.\n",
    "\n",
    "        Args:\n",
    "            inputs_db: `INPUTS` data group in the h5 file.\n",
    "            index (int): event index.\n",
    "\n",
    "        :rtype: :class:`torch.tensor`\n",
    "        \"\"\"\n",
    "        x = torch.concatenate(\n",
    "            [ torch.tensor(np.array(inputs_db[obj][index].tolist()),dtype=torch.float32) for obj in self.objects ],\n",
    "            dim=0\n",
    "        )\n",
    "        return x[x[:,-1]!=0]\n",
    "\n",
    "    def get_edge_feats(self, x: Tensor) -> Tuple[Tensor,Tensor]:\n",
    "        r\"\"\"Build a fully connected graph, and get edge feature and index tensors.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): node feature tensor.\n",
    "\n",
    "        :rtype: :class:`Tuple[torch.tensor,torch.tensor]`\n",
    "        \"\"\"\n",
    "        num_nodes = x.size(dim=0)\n",
    "        edge_index = torch.tensor(list(permutations(range(num_nodes),r=2)),dtype=torch.int64).permute(dims=(1,0))\n",
    "\n",
    "        edge_i = MomentumTensor.EEtaPhiPt(x[:,0:4].index_select(0, index=edge_index[0]))\n",
    "        edge_j = MomentumTensor.EEtaPhiPt(x[:,0:4].index_select(0, index=edge_index[1]))\n",
    "\n",
    "        # Get edge embedding\n",
    "        embedding = EdgeEmbedding(edge_i, edge_j)\n",
    "        edge_attr = torch.concatenate(\n",
    "            [ embedding.dEta(), embedding.dPhi(), embedding.dR(), embedding.M(), embedding.theta_p() ],\n",
    "            dim=1\n",
    "        )\n",
    "        return edge_attr, edge_index\n",
    "\n",
    "    def get_global_feats(self, inputs_db, index: int) -> Tensor:\n",
    "        r\"\"\"Get global features.\n",
    "\n",
    "        Args:\n",
    "            inputs_db: `INPUTS` data group in the h5 file.\n",
    "            index (int): event index.\n",
    "\n",
    "        :rtype: :class:`torch.tensor`\n",
    "        \"\"\"\n",
    "        return torch.tensor(np.array(inputs_db['global'][index].tolist()),dtype=torch.float32)\n",
    "\n",
    "    def get_VertexID(self, labels_db, index: int) -> Tensor:\n",
    "        r\"\"\"Get object IDs.\n",
    "\n",
    "        Args:\n",
    "            labels_db: `LABELS` data group in the h5 file.\n",
    "            index (int): event index.\n",
    "\n",
    "        :rtype: :class:`torch.tensor`\n",
    "        \"\"\"\n",
    "        ids = torch.tensor(np.array(labels_db['VertexID'][index]), dtype=torch.float32)\n",
    "        return ids[ids!=-9].reshape(-1,1)\n",
    "\n",
    "    def get_edge_labels(\n",
    "        self,\n",
    "        edge_index: Tensor,\n",
    "        VertexID: Tensor\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Get edge labels.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.tensor): edge indices.\n",
    "            VertexID (torch.tensor): node types.\n",
    "\n",
    "        :rtype: :class:`torch.tensor`\n",
    "        \"\"\"\n",
    "        endpoints_ids = torch.concatenate([2**VertexID.index_select(0,index=edge_index[0]), 2**VertexID.index_select(0,index=edge_index[1])],dim=1).sum(dim=1)\n",
    "        target_idx = torch.concatenate(\n",
    "            [ torch.argwhere(endpoints_ids==id) for id in self.edge_identifiers ]\n",
    "        ).squeeze()\n",
    "        # Scatter the edge labels in a empty tensor\n",
    "        return torch.zeros(endpoints_ids.size(), dtype=torch.float32).scatter(dim=0, index=target_idx, src=torch.full(target_idx.size(), 1, dtype=torch.float32)).reshape(-1,1)\n",
    "\n",
    "    def get_hyperedge_labels(\n",
    "        self,\n",
    "        VertexID: Tensor\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Get hyperedge labels.\n",
    "\n",
    "        Args:\n",
    "            VertexID (torch.tensor): node types.\n",
    "            identifiers (List): integer hyperedge identification value.\n",
    "\n",
    "        :rtype: :class:`torch.tensor`\n",
    "        \"\"\"\n",
    "        num_nodes = VertexID.size(dim=0)\n",
    "        hyperedge_index = torch.tensor(list(combinations(range(num_nodes),r=self.hyperedge_order)),dtype=torch.int64).permute(dims=(1,0))\n",
    "\n",
    "        endpoints_ids = torch.concatenate(\n",
    "            [ 2**VertexID.index_select(0, index=hyperedge_index[row]) for row in range(self.hyperedge_order) ],\n",
    "            dim=1\n",
    "        ).sum(dim=1)\n",
    "        target_idx = torch.concatenate(\n",
    "            [ torch.argwhere(endpoints_ids==id) for id in self.hyperedge_identifiers ]\n",
    "        ).squeeze()\n",
    "\n",
    "        hyperegde_t = torch.zeros(endpoints_ids.size(), dtype=torch.float32).scatter(dim=0, index=target_idx, src=torch.full(target_idx.size(), 1, dtype=torch.float32)).reshape(-1,1)\n",
    "        return hyperegde_t, hyperedge_index\n",
    "\n",
    "    def scale_features(self, src: Tensor, scaling_methods: List):\n",
    "        for feature_idx in range(len(scaling_methods)):\n",
    "            if scaling_methods[feature_idx].lower() == \"log\":\n",
    "                src[:,feature_idx] = torch.log(src[:,feature_idx])\n",
    "            elif scaling_methods[feature_idx].lower() == \"pi\":\n",
    "                src[:,feature_idx] = src[:,feature_idx]/torch.pi\n",
    "            elif re.search(r'\\d+', scaling_methods[feature_idx].lower()):\n",
    "                src[:,feature_idx] = src[:,feature_idx]/int(re.search(r'\\d+', scaling_methods[feature_idx].lower()).group())\n",
    "            elif scaling_methods[feature_idx].lower() == \"none\":\n",
    "                pass\n",
    "            else:\n",
    "                warnings.warn(\"%s is not available, scale is not applied.. Available methods are: `log`, `pi` (divide by pi), `dN` (divide by N) and `none`.\"%(scaling_methods[feature_idx]))\n",
    "        return src\n",
    "\n",
    "    def __getitem__(self, index) -> Tensor:\n",
    "        with h5py.File(self.file_path, 'r') as file:\n",
    "            if self.use_index_select:\n",
    "                index = self.index_select[index]\n",
    "\n",
    "            x = self.get_node_feats(file['INPUTS'], index)\n",
    "            u = self.get_global_feats(file['INPUTS'], index)\n",
    "            VertexID = self.get_VertexID(file['LABELS'], index)\n",
    "\n",
    "        edge_attr, edge_index = self.get_edge_feats(x)\n",
    "        edge_attr_t = self.get_edge_labels(edge_index, VertexID)\n",
    "        x_t, hyperedge_index = self.get_hyperedge_labels(VertexID)\n",
    "\n",
    "        x = self.scale_features(x, scaling_methods=self.node_scalings)\n",
    "        u = self.scale_features(u, scaling_methods=self.global_scalings)\n",
    "        edge_attr = self.scale_features(edge_attr, scaling_methods=['none','none','none','log'])\n",
    "\n",
    "        return Data(x_s=x, num_nodes=x.size(dim=0), edge_attr_s=edge_attr, edge_index=edge_index, edge_index_h=hyperedge_index, u_s=u, edge_attr_t=edge_attr_t, x_t=x_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
