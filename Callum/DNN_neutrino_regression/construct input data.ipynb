{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CURRENTLY:\n",
    "\n",
    "-takes in SN, EM, NW reconstruction px,py,pz. If nan then converts it to 0 pre scale application\n",
    "\n",
    "-total of 18 parameters per event \n",
    "\n",
    "-outputs 6 bits of data: px,py,pz for nu/nubar\n",
    "\n",
    "\n",
    "\n",
    "ADDITTION:\n",
    "\n",
    "-Have added in met_met, met_phi, lep_p1_1 and lep_pt_2\n",
    "\n",
    "\n",
    "\n",
    "TEST:\n",
    "\n",
    "-then plotted difference in px and pt from truth for EM, SM, NW and output.\n",
    "\n",
    "-But here remove events that are not properly reconstructed by the EM, SN, NW models for all\n",
    "\n",
    "\n",
    "\n",
    "IMPROVMENTS:\n",
    "\n",
    "-Try doing DNN output of pt, eta, phi? (probably limited difference)?\n",
    "\n",
    "-add in mu sqaures?\n",
    "\n",
    "-add in extra kinematics?\n",
    "\n",
    "-try cutting out useles data before training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import vector\n",
    "import awkward as ak\n",
    "import uproot\n",
    "import boost_histogram as bh\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/broad/Documents/Documents/university/summer work/DNN_used/final_using_DNN_folder/\"\n",
    "file = h5py.File(path+'callum_neutrinos.h5', 'r')\n",
    "mu_squared_eventnumber = np.array(file[\"eventNumber\"])\n",
    "mu_squared = np.array(file[\"neutrinos\"])\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treenominal = uproot.open(path+\"ttbar_skimmed_july9_v2.root:nominal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot.open(path+\"ttbar_skimmed_july9_v2.root:truth\")\n",
    "treerecon = uproot.open(path+\"ttbar_skimmed_july9_v2.root:recon\")\n",
    "mask_truth_in_recon = np.isin(tree[\"eventNumber\"].array(),treerecon[\"eventNumber\"].array())\n",
    "mask_recon_in_truth = np.isin(treerecon[\"eventNumber\"].array(), tree[\"eventNumber\"].array())\n",
    "mask_nominal_in_truth=mask_recon_in_truth\n",
    "nu_truth = vector.zip({'pt': tree[\"nu_pt\"].array(), 'eta': tree[\"nu_eta\"].array(), 'phi': tree[\"nu_phi\"].array(), 'm': tree[\"nu_mass\"].array()})[mask_truth_in_recon]\n",
    "nubar_truth = vector.zip({'pt': tree[\"nubar_pt\"].array(), 'eta': tree[\"nubar_eta\"].array(), 'phi': tree[\"nubar_phi\"].array(), 'm': tree[\"nubar_mass\"].array()})[mask_truth_in_recon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_EM = vector.zip({'pt': treerecon[\"EM_nu_pt\"].array(), 'eta': treerecon[\"EM_nu_eta\"].array(), 'phi': treerecon[\"EM_nu_phi\"].array(), 'm': treerecon[\"EM_nu_m\"].array()})[mask_recon_in_truth]\n",
    "nubar_EM = vector.zip({'pt': treerecon[\"EM_nubar_pt\"].array(), 'eta': treerecon[\"EM_nubar_eta\"].array(), 'phi': treerecon[\"EM_nubar_phi\"].array(), 'm': treerecon[\"EM_nubar_m\"].array()})[mask_recon_in_truth]\n",
    "nu_SN = vector.zip({'pt': treerecon[\"SN_nu_pt\"].array(), 'eta': treerecon[\"SN_nu_eta\"].array(), 'phi': treerecon[\"SN_nu_phi\"].array(), 'm': treerecon[\"SN_nu_m\"].array()})[mask_recon_in_truth]\n",
    "nubar_SN = vector.zip({'pt': treerecon[\"SN_nubar_pt\"].array(), 'eta': treerecon[\"SN_nubar_eta\"].array(), 'phi': treerecon[\"SN_nubar_phi\"].array(), 'm': treerecon[\"SN_nubar_m\"].array()})[mask_recon_in_truth]\n",
    "nu_NW = vector.zip({'pt': treerecon[\"NW_nu_pt\"].array(), 'eta': treerecon[\"NW_nu_eta\"].array(), 'phi': treerecon[\"NW_nu_phi\"].array(), 'm': treerecon[\"NW_nu_m\"].array()})[mask_recon_in_truth]\n",
    "nubar_NW = vector.zip({'pt': treerecon[\"NW_nubar_pt\"].array(), 'eta': treerecon[\"NW_nubar_eta\"].array(), 'phi': treerecon[\"NW_nubar_phi\"].array(), 'm': treerecon[\"NW_nubar_m\"].array()})[mask_recon_in_truth]\n",
    "\n",
    "met_met = treenominal[\"met_met\"].array()\n",
    "met_phi = treenominal[\"met_phi\"].array()\n",
    "lep_pt_1  = treenominal[\"lep_pt\"].array()[:,0]\n",
    "lep_pt_2 = treenominal[\"lep_pt\"].array()[:,1]\n",
    "lep_eta_1 = treenominal[\"lep_eta\"].array()[:,0]\n",
    "lep_eta_2 = treenominal[\"lep_eta\"].array()[:,1]\n",
    "lep_phi_1 = treenominal[\"lep_phi\"].array()[:,0]\n",
    "lep_phi_2 = treenominal[\"lep_phi\"].array()[:,1]\n",
    "\n",
    "# #OPTIONAL DONE NOW SO I CAN COMPARE DNN RESULTS TO NEUTRONS!\n",
    "remove_un_found_events_mask = ((nu_EM.pt>-1) & (nu_EM.pt>-1) & (nu_SN.pt>-1) & (nu_SN.pt>-1) & (nu_NW.pt>-1) & (nu_NW.pt>-1))\n",
    "nu_EM = nu_EM[remove_un_found_events_mask]\n",
    "nubar_EM = nubar_EM[remove_un_found_events_mask]\n",
    "nu_SN = nu_SN[remove_un_found_events_mask]\n",
    "nubar_SN = nubar_SN[remove_un_found_events_mask]\n",
    "nu_NW = nu_NW[remove_un_found_events_mask]\n",
    "nubar_NW = nubar_NW[remove_un_found_events_mask]\n",
    "met_met =met_met[remove_un_found_events_mask]\n",
    "met_phi =met_phi[remove_un_found_events_mask]\n",
    "lep_pt_1 =lep_pt_1[remove_un_found_events_mask]\n",
    "lep_pt_2 =lep_pt_2[remove_un_found_events_mask]\n",
    "nu_truth= nu_truth[remove_un_found_events_mask]\n",
    "nubar_truth=nubar_truth[remove_un_found_events_mask]\n",
    "lep_eta_1 =lep_eta_1[remove_un_found_events_mask]\n",
    "lep_eta_2 =lep_eta_2[remove_un_found_events_mask]\n",
    "lep_phi_1 =lep_phi_1[remove_un_found_events_mask]\n",
    "lep_phi_2 =lep_phi_2[remove_un_found_events_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(tree[\"eventNumber\"].array()[mask_truth_in_recon][remove_un_found_events_mask], columns=['eventNumber'])\n",
    "csv_file_path = 'C:/Users/broad/Downloads/neutrino_eventnumber'\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset with pt, phi, eta for DNN\n",
    "length=len(nu_EM)/2\n",
    "length_test=len(nu_EM)-length\n",
    "h5_file = h5py.File(\"DNN_train_data_v2.h5\", 'w')\n",
    "group1 = h5_file.create_group('recon')\n",
    "group1.create_dataset(\"nu_EM_px\", data=nu_EM.px[:length])\n",
    "group1.create_dataset(\"nu_EM_py\", data=nu_EM.py[:length])\n",
    "group1.create_dataset(\"nu_EM_pz\", data=nu_EM.pz[:length])\n",
    "group1.create_dataset(\"nu_SN_px\", data=nu_SN.px[:length])\n",
    "group1.create_dataset(\"nu_SN_py\", data=nu_SN.py[:length])\n",
    "group1.create_dataset(\"nu_SN_pz\", data=nu_SN.pz[:length])\n",
    "group1.create_dataset(\"nu_NW_px\", data=nu_NW.px[:length])\n",
    "group1.create_dataset(\"nu_NW_py\", data=nu_NW.py[:length])\n",
    "group1.create_dataset(\"nu_NW_pz\", data=nu_NW.pz[:length])\n",
    "\n",
    "group1.create_dataset(\"nubar_EM_px\", data=nubar_EM.px[:length])\n",
    "group1.create_dataset(\"nubar_EM_py\", data=nubar_EM.py[:length])\n",
    "group1.create_dataset(\"nubar_EM_pz\", data=nubar_EM.pz[:length])\n",
    "group1.create_dataset(\"nubar_SN_px\", data=nubar_SN.px[:length])\n",
    "group1.create_dataset(\"nubar_SN_py\", data=nubar_SN.py[:length])\n",
    "group1.create_dataset(\"nubar_SN_pz\", data=nubar_SN.pz[:length])\n",
    "group1.create_dataset(\"nubar_NW_px\", data=nubar_NW.px[:length])\n",
    "group1.create_dataset(\"nubar_NW_py\", data=nubar_NW.py[:length])\n",
    "group1.create_dataset(\"nubar_NW_pz\", data=nubar_NW.pz[:length])\n",
    "\n",
    "\n",
    "group1.create_dataset(\"met_met\", data=met_met[:length])\n",
    "group1.create_dataset(\"met_phi\", data=met_phi[:length])\n",
    "group1.create_dataset(\"lep_pt_1\", data=lep_pt_1[:length])\n",
    "group1.create_dataset(\"lep_pt_2\", data=lep_pt_2[:length])\n",
    "group1.create_dataset(\"lep_eta_1\", data=lep_eta_1[:length])\n",
    "group1.create_dataset(\"lep_eta_2\", data=lep_eta_2[:length])\n",
    "group1.create_dataset(\"lep_phi_1\", data=lep_phi_1[:length])\n",
    "group1.create_dataset(\"lep_phi_2\", data=lep_phi_2[:length])\n",
    "\n",
    "\n",
    "group2 = h5_file.create_group('truth')\n",
    "group2.create_dataset(\"nu_truth_px\", data=nu_truth.px[:length])\n",
    "group2.create_dataset(\"nu_truth_py\", data=nu_truth.py[:length])\n",
    "group2.create_dataset(\"nu_truth_pz\", data=nu_truth.pz[:length])\n",
    "group2.create_dataset(\"nubar_truth_px\", data=nubar_truth.px[:length])\n",
    "group2.create_dataset(\"nubar_truth_py\", data=nubar_truth.py[:length])\n",
    "group2.create_dataset(\"nubar_truth_pz\", data=nubar_truth.pz[:length])\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset with px, py, pz for DNN\n",
    "length_test=len(nu_EM)-length\n",
    "h5_file = h5py.File(\"DNN_test_data_v2.h5\", 'w')\n",
    "group1 = h5_file.create_group('recon')\n",
    "group1.create_dataset(\"nu_EM_px\", data=nu_EM.px[-length_test:])\n",
    "group1.create_dataset(\"nu_EM_py\", data=nu_EM.py[-length_test:])\n",
    "group1.create_dataset(\"nu_EM_pz\", data=nu_EM.pz[-length_test:])\n",
    "group1.create_dataset(\"nu_SN_px\", data=nu_SN.px[-length_test:])\n",
    "group1.create_dataset(\"nu_SN_py\", data=nu_SN.py[-length_test:])\n",
    "group1.create_dataset(\"nu_SN_pz\", data=nu_SN.pz[-length_test:])\n",
    "group1.create_dataset(\"nu_NW_px\", data=nu_NW.px[-length_test:])\n",
    "group1.create_dataset(\"nu_NW_py\", data=nu_NW.py[-length_test:])\n",
    "group1.create_dataset(\"nu_NW_pz\", data=nu_NW.pz[-length_test:])\n",
    "\n",
    "group1.create_dataset(\"nubar_EM_px\", data=nubar_EM.px[-length_test:])\n",
    "group1.create_dataset(\"nubar_EM_py\", data=nubar_EM.py[-length_test:])\n",
    "group1.create_dataset(\"nubar_EM_pz\", data=nubar_EM.pz[-length_test:])\n",
    "group1.create_dataset(\"nubar_SN_px\", data=nubar_SN.px[-length_test:])\n",
    "group1.create_dataset(\"nubar_SN_py\", data=nubar_SN.py[-length_test:])\n",
    "group1.create_dataset(\"nubar_SN_pz\", data=nubar_SN.pz[-length_test:])\n",
    "group1.create_dataset(\"nubar_NW_px\", data=nubar_NW.px[-length_test:])\n",
    "group1.create_dataset(\"nubar_NW_py\", data=nubar_NW.py[-length_test:])\n",
    "group1.create_dataset(\"nubar_NW_pz\", data=nubar_NW.pz[-length_test:])\n",
    "\n",
    "\n",
    "group1.create_dataset(\"met_met\", data=met_met[-length_test:])\n",
    "group1.create_dataset(\"met_phi\", data=met_phi[-length_test:])\n",
    "group1.create_dataset(\"lep_pt_1\", data=lep_pt_1[-length_test:])\n",
    "group1.create_dataset(\"lep_pt_2\", data=lep_pt_2[-length_test:])\n",
    "group1.create_dataset(\"lep_eta_1\", data=lep_eta_1[-length_test:])\n",
    "group1.create_dataset(\"lep_eta_2\", data=lep_eta_2[-length_test:])\n",
    "group1.create_dataset(\"lep_phi_1\", data=lep_phi_1[-length_test:])\n",
    "group1.create_dataset(\"lep_phi_2\", data=lep_phi_2[-length_test:])\n",
    "\n",
    "\n",
    "group2 = h5_file.create_group('truth')\n",
    "group2.create_dataset(\"nu_truth_px\", data=nu_truth.px[-length_test:])\n",
    "group2.create_dataset(\"nu_truth_py\", data=nu_truth.py[-length_test:])\n",
    "group2.create_dataset(\"nu_truth_pz\", data=nu_truth.pz[-length_test:])\n",
    "group2.create_dataset(\"nubar_truth_px\", data=nubar_truth.px[-length_test:])\n",
    "group2.create_dataset(\"nubar_truth_py\", data=nubar_truth.py[-length_test:])\n",
    "group2.create_dataset(\"nubar_truth_pz\", data=nubar_truth.pz[-length_test:])\n",
    "group2.create_dataset(\"eventnumber\", data=tree[\"eventNumber\"].array()[mask_truth_in_recon][remove_un_found_events_mask][-length_test:])\n",
    "\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[1116768,\n",
       " 1116436,\n",
       " 1116242,\n",
       " 1114804,\n",
       " 1114820,\n",
       " 1116828,\n",
       " 1116296,\n",
       " 1114840,\n",
       " 1116211,\n",
       " 1114178,\n",
       " ...,\n",
       " 47057019,\n",
       " 47056352,\n",
       " 47057507,\n",
       " 47057931,\n",
       " 47056050,\n",
       " 47056697,\n",
       " 47056325,\n",
       " 47056749,\n",
       " 47057539]\n",
       "---------------------\n",
       "type: 770552 * uint64</pre>"
      ],
      "text/plain": [
       "<Array [1116768, 1116436, ..., 47056749, 47057539] type='770552 * uint64'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree[\"eventNumber\"].array()[mask_truth_in_recon][remove_un_found_events_mask][-length_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
