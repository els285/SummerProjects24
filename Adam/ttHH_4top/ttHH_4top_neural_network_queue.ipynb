{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot \n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "import torch\n",
    "import torch_hep\n",
    "import torch_geometric\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\internships\\\\summer internship\\\\making cuts\\\\ttHH_tttt\\\\'\n",
    "tree_tthh = uproot.open(path + 'ttHH_combined.root:AnalysisMiniTree')\n",
    "tree_4top = uproot.open(path + '4top_aMCPy8EG_SSML.root:reco')\n",
    "\n",
    "\n",
    "selection = [branch for branch in tree_tthh.keys() if 'Jet' in branch and 'NOSYS' in branch]\n",
    "\n",
    "# # 'ttHH_nJets_NOSYS'\n",
    "# # 'ttHH_nBJets_NOSYS'\n",
    "# tree_tthh['ttHH_nBJets_NOSYS'].array()\n",
    "# len(tree_tthh.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(type, tree, parameters, string):\n",
    "    array = []\n",
    "    for i in parameters:\n",
    "        array.append(tree[f'{string[0]}_{type}_{i}_{string[1]}'].array())\n",
    "    return vector.zip({param:array[j] for j, param in enumerate(parameters)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lepton1 = create_vector('Lepton1', tree_tthh, ['pt','eta','phi','E'], ['ttHH', 'NOSYS'])\n",
    "lepton2 = create_vector('Lepton2', tree_tthh, ['pt','eta','phi','E'], ['ttHH', 'NOSYS'])\n",
    "\n",
    "bjet1 = create_vector('Jet_b1', tree_tthh, ['pt','eta','phi','E'], ['ttHH', 'NOSYS'])\n",
    "bjet2 = create_vector('Jet_b2', tree_tthh, ['pt','eta','phi','E'], ['ttHH', 'NOSYS'])\n",
    "bjet3 = create_vector('Jet_b3', tree_tthh, ['pt','eta','phi','E'], ['ttHH', 'NOSYS'])\n",
    "bjet4 = create_vector('Jet_b4', tree_tthh, ['pt','eta','phi','E'], ['ttHH', 'NOSYS'])\n",
    "\n",
    "cut_m = (lepton1.m >0) & (lepton2.m > 0) & (bjet1.m >0) & (bjet2.m >0) & (bjet3.m >0) & (bjet4.m >0)\n",
    "cut_pt = (lepton1.pt >0) & (lepton2.pt > 0) & (bjet1.pt >0) & (bjet2.pt >0) & (bjet3.pt >0) & (bjet4.pt >0)\n",
    "cut_eta = (lepton1.eta >-5) & (lepton2.eta > -5) & (bjet1.eta >-5) & (bjet2.eta >-5) & (bjet3.eta >-5) & (bjet4.eta >-5)\n",
    "cut_phi = (lepton1.phi >-5) & (lepton2.phi > -5) & (bjet1.phi >-5) & (bjet2.phi >-5) & (bjet3.phi >-5) & (bjet4.phi >-5)\n",
    "mask_tthh = cut_m & cut_pt & cut_eta & cut_phi\n",
    "\n",
    "lepton1, lepton2, bjet1, bjet2, bjet3, bjet4 = lepton1[mask_tthh], lepton2[mask_tthh], bjet1[mask_tthh], bjet2[mask_tthh], bjet3[mask_tthh], bjet4[mask_tthh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entry1(entries, tree, string):\n",
    "    dic = {}\n",
    "    for entry in entries:\n",
    "        dic[entry] = np.stack([tree[f'{string[0]}_{type}_{entry}_{string[1]}'].array()[mask_tthh] for type in ['Jet_b1','Jet_b2','Jet_b3','Jet_b4', 'Lepton1','Lepton2']], axis=1)\n",
    "    return dic\n",
    "\n",
    "def create_entry2(entries, tree, mask):\n",
    "    dic = {}\n",
    "    el_mu = np.concatenate([tree[f'el_pt_NOSYS'].array()[mask], tree['mu_pt_NOSYS'].array()[mask]], axis = 1)\n",
    "    dic['pt'] = np.concatenate([tree[f'truth_jet_pt'].array()[mask][:,0:4], el_mu], axis = 1)\n",
    "    for entry in entries[1:]:\n",
    "        el_mu = np.concatenate([tree[f'el_{entry}'].array()[mask], tree[f'mu_{entry}'].array()[mask]], axis = 1)\n",
    "        dic[entry] = np.concatenate([tree[f'truth_jet_{entry}'].array()[mask][:,0:4], el_mu], axis=1)\n",
    "    return dic\n",
    "    # probably need to order electrons and muons based on pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic_tthh = create_entry1(['pt', 'eta', 'phi', 'E'], tree_tthh, ['ttHH', 'NOSYS'])\n",
    "# , 'pdgid', 'charge', 'btagged\n",
    "length_tthh = len(dic_tthh['pt'])\n",
    "a = (np.abs(tree_tthh['ttHH_Lepton1_pdgid_NOSYS'].array()[mask_tthh]) == 11)*1+(np.abs(tree_tthh['ttHH_Lepton1_pdgid_NOSYS'].array()[mask_tthh]) == 13)*2\n",
    "b = (np.abs(tree_tthh['ttHH_Lepton1_pdgid_NOSYS'].array()[mask_tthh]) == 11)*1+(np.abs(tree_tthh['ttHH_Lepton1_pdgid_NOSYS'].array()[mask_tthh]) == 13)*2\n",
    "dic_tthh['type'] = np.transpose(np.vstack((np.zeros((length_tthh,4)).T, a, b)))\n",
    "charge1 = tree_tthh['ttHH_Lepton1_charge_NOSYS'].array()[mask_tthh]\n",
    "charge2 = tree_tthh['ttHH_Lepton2_charge_NOSYS'].array()[mask_tthh]\n",
    "dic_tthh['charge'] = np.transpose(np.vstack((np.zeros((length_tthh,4)).T, charge1, charge2)))\n",
    "dic_tthh['b'] = np.concatenate([np.ones((length_tthh,4)), np.zeros((length_tthh, 2))], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tttt = (ak.num(tree_4top['truth_jet_pt'].array(), axis = 1) >= 4) & (ak.num(tree_4top['el_pt_NOSYS'].array(), axis = 1) + ak.num(tree_4top['mu_pt_NOSYS'].array(), axis = 1) == 2)\n",
    "dic_tttt = create_entry2(['pt', 'eta', 'phi', 'e'], tree_4top, mask_tttt)\n",
    "length_tttt = len(dic_tttt['pt'])\n",
    "num_el = ak.num(tree_4top['el_pt_NOSYS'].array()[mask_tttt], axis=1)\n",
    "dic_tttt['type'] = np.hstack((np.zeros((length_tttt,4)), np.stack([np.ones((length_tttt)) * (num_el ==0)+1, np.ones((length_tttt)) * (num_el <2)+1], axis=1)))\n",
    "dic_tttt['charge'] = np.concatenate([np.zeros((length_tttt,4)), tree_4top['el_charge'].array()[mask_tttt], tree_4top['mu_charge'].array()[mask_tttt]], axis=1)\n",
    "dic_tttt['b'] = np.concatenate([np.ones((length_tttt,4)), np.zeros((length_tttt, 2))], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "\n",
    "for i in range(length_tthh):\n",
    "    G = torch_hep.graph.GraphBuilder()\n",
    "    G.add_asNode(key='x', pt = dic_tthh['pt'][i], eta = dic_tthh['eta'][i], phi = dic_tthh['phi'][i], E = dic_tthh['E'][i], type = dic_tthh['type'][i], charge = dic_tthh['charge'][i], b = dic_tthh['b'][i],dtype=torch.float32)\n",
    "    G.add_asEdge(key='edge_attrs', index=list(itertools.permutations(range(len(dic_tthh['pt'][i])),2)), dtype=torch.int64)\n",
    "    G.add_asGlobal(key='y', IsSIG=1, dtype=torch.float32)\n",
    "    # G.add_asGlobal(key='w', weight=1, dtype=torch.float32)\n",
    "\n",
    "    dataset.append(G.to_Data())\n",
    "\n",
    "for i in range(length_tttt):\n",
    "    G = torch_hep.graph.GraphBuilder()\n",
    "    G.add_asNode(key='x', pt = dic_tttt['pt'][i] ,eta = dic_tttt['eta'][i], phi = dic_tttt['phi'][i] , E = dic_tttt['e'][i], type = dic_tttt['type'][i], charge = dic_tttt['charge'][i], b = dic_tttt['b'][i],dtype=torch.float32)\n",
    "    G.add_asEdge(key='edge_attrs', index=list(itertools.permutations(range(len(dic_tttt['pt'][i])),2)), dtype=torch.int64)\n",
    "    G.add_asGlobal(key='y', IsSIG=0, dtype=torch.float32)\n",
    "    # G.add_asGlobal(key='w', weight=0.12, dtype=torch.float32)\n",
    "\n",
    "    dataset.append(G.to_Data())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 47046\n",
      "Number of test graphs: 11762\n",
      "percentage of graphs that are signal: 10.98%\n"
     ]
    }
   ],
   "source": [
    "seed = 1415\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(dataset)\n",
    "cutoff = int(len(dataset)*0.8)\n",
    "#cutoff = 1000\n",
    "\n",
    "train_dataset = dataset[:cutoff]\n",
    "test_dataset = dataset[cutoff:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "print(f'percentage of graphs that are signal: {100* length_tthh/(length_tthh + length_tttt):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "scaler_loader = [i for i in DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)][0]\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(scaler_loader.x)\n",
    "total_loader = [i for i in DataLoader(dataset, batch_size=len(dataset), shuffle=True)][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(GCNConv(7, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'GCN'\n",
    "    \n",
    "class Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(Graph, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(GraphConv(7, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(GraphConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'GRAPH'\n",
    "    #GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(GAT, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(GATConv(7, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(GATConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'GAT'\n",
    "    \n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(SAGEConv(7, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'SAGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCN'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCN(hidden_channels=64, num_convs=3)\n",
    "GCN.__str__(GCN)\n",
    "model = GCN\n",
    "model.__str__(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(out_numpy, all_y, zoomed = False):\n",
    "    hep.style.use(hep.style.ATLAS)\n",
    "    if zoomed:\n",
    "        hist1 = bh.Histogram(bh.axis.Regular(50, 0.98, 1)) # Initialises empty histogram with 50 bins spanning [0,500]\n",
    "        hist2 = bh.Histogram(bh.axis.Regular(50, 0.98, 1))\n",
    "    else:\n",
    "        hist1 = bh.Histogram(bh.axis.Regular(5, 0, 1)) # Initialises empty histogram with 50 bins spanning [0,500]\n",
    "        hist2 = bh.Histogram(bh.axis.Regular(5, 0, 1))\n",
    "    hist1.fill(out_numpy[all_y==1])    # Fills the histogram with some data\n",
    "    hist2.fill(out_numpy[all_y ==0])\n",
    "\n",
    "\n",
    "    hep.histplot([hist1/hist1.size, hist2/hist2.size], label = ['signal', 'background'])\n",
    "    plt.xlabel('signal confidence')\n",
    "    plt.ylabel('Normalized Frequency')\n",
    "    plt.title(f'signal background plot')\n",
    "    plt.legend()\n",
    "    #plt.xlim(0,1)\n",
    "    #plt.savefig(f'using_adam_images\\{dim} signal background zoomed.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import BinaryAccuracy\n",
    "def train(model, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    #out_numpy = np.array([])\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        optimizer.zero_grad()  # Clear gradients.    \n",
    "        x_transformed = torch.tensor(scaler.transform(data.x),dtype=torch.float32)\n",
    "        out = model(x_transformed, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        # loss = torch.sum(criterion(out, data.y.reshape(-1,1))*data.w.reshape(-1,1)) / data.w.sum()# Compute the loss.\n",
    "        loss = criterion(out, data.y.reshape(-1,1))\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "    return model\n",
    "        \n",
    "\n",
    "def test(model, criterion, loader, output = ''):\n",
    "    model.eval()\n",
    "    metric = BinaryAccuracy()\n",
    "\n",
    "    preds_array = np.array([])\n",
    "    total_loss = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        x_transformed = torch.tensor(scaler.transform(data.x),dtype=torch.float32)\n",
    "        out = model(x_transformed, data.edge_index, data.batch)\n",
    "        preds = (out.cpu().detach().numpy()>0.5)[:,0]*1\n",
    "        preds_array = np.hstack((preds_array, preds))\n",
    "        metric.update(out.flatten(), data.y)\n",
    "        loss = criterion(out, data.y.reshape(-1,1))\n",
    "        total_loss += loss.item() * data.size(0)\n",
    "    total_loss /= len(loader.dataset)\n",
    "    signal_rate = np.sum(preds_array>0.5)/len(preds_array)\n",
    "    accuracy = metric.compute()\n",
    "    if output:\n",
    "        print(f'{output} accuracy: {100*accuracy:.3f}% , loss: {total_loss:.4f}, signal rate: {100*signal_rate:.2f}% ')\n",
    "\n",
    "    return accuracy.item(), total_loss, signal_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_comparison(class_type, layers, hidden_dims, train_loss, test_loss, train_acc, test_acc, b_prec, b_recall, s_prec, s_recall, training_time, epoch):\n",
    "    file_path = 'performance_comparison.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        print('hi')\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        print('by')\n",
    "\n",
    "\n",
    "    # Data to append\n",
    "    data_to_append = {\n",
    "        'class type': [class_type.__str__(class_type)],\n",
    "        'layers': [layers],\n",
    "        'hidden_dims': [hidden_dims],\n",
    "        'training loss' : [train_loss],\n",
    "        'training accuracy' : [train_acc],\n",
    "        'test cost' : [test_loss],\n",
    "        'training accuracy': [train_acc],\n",
    "        'test accuracy': [test_acc],\n",
    "        'training time': [training_time],\n",
    "        'background precision': [b_prec],\n",
    "        'background recall': [b_recall],\n",
    "        'signal precision': [s_prec],\n",
    "        'signal recall': [s_recall],\n",
    "        'training time per epoch' : [training_time],\n",
    "        'epochs':[epoch+1]\n",
    "    }\n",
    "\n",
    "    df_to_append = pd.DataFrame(data_to_append)\n",
    "    df = df.dropna(how='all', axis=1)\n",
    "    df_to_append = df_to_append.dropna(how='all', axis=1)\n",
    "\n",
    "    # Concatenate the existing DataFrame with the new data\n",
    "    df = pd.concat([df, df_to_append], ignore_index=True)\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each epoch:\n",
    "train accuracy, train loss, train signal rate\n",
    "test accuracy, test loss, test signal rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN\n",
    "------------\n",
    "- move graphs onto this program\n",
    "    - roc, accuracy over epochs, cost over epochs\n",
    "\n",
    "- move the array of cost an accuracy to the initialisation of the model, so it keeps all the training data\n",
    "- write a general function ot test different numbers of hidden layers, plot results, save results to an excel\n",
    "- try all above for cp odd and cp even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_background(test_results, train_results, decisions_nn, test_y, class_type, layers, hidden_dims):\n",
    "    fpr_nn, tpr_nn, thresholds_nn = sklearn.metrics.roc_curve(test_y, decisions_nn)\n",
    "    # may need decisions to be 2 dimensional\n",
    "    class_str = class_type.__str__(class_type)\n",
    "\n",
    "    plt.plot(fpr_nn, tpr_nn, linestyle=\"dashed\", label=\"Neural Network\")  # plot neural network ROC\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"dotted\", color=\"grey\", label=\"Luck\")  # plot diagonal line to indicate luck\n",
    "    plt.xlabel(\"False Positive Rate\")  # x-axis label\n",
    "    plt.ylabel(\"True Positive Rate\")  # y-axis label\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(f'{class_str}, layers {layers}, dims {hidden_dims} ROC plot')\n",
    "    plt.grid()  # add a grid to the plot\n",
    "    plt.legend()  # add a legend\n",
    "    plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} ROC plot.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(np.arange(len(train_results)), train_results[:,1],linestyle='-', marker='o',  label = 'train loss')\n",
    "    plt.plot(np.arange(len(test_results)), test_results[:,1], linestyle='-', marker='o', label = 'test loss')\n",
    "    plt.xlabel(\"Epochs\")  # x-axis label\n",
    "    plt.ylabel(\"Loss\")  # y-axis label\n",
    "    plt.title(f'Loss at each Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} loss at each epoch.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(len(train_results)), train_results[:,0],linestyle='-', marker='o',  label = 'train accuracy')\n",
    "    plt.plot(np.arange(len(train_results)), train_results[:,0], linestyle='-', marker='o', label = 'test accuracy')\n",
    "    plt.xlabel(\"Epochs\")  # x-axis label\n",
    "    plt.ylabel(\"Percentage Accuracy\")  # y-axis label\n",
    "    plt.title(f'Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} accuracy at each epoch.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    hep.style.use(hep.style.ATLAS)\n",
    "\n",
    "    hist1 = bh.Histogram(bh.axis.Regular(5, 0, 1)) # Initialises empty histogram with 50 bins spanning [0,500]\n",
    "    hist2 = bh.Histogram(bh.axis.Regular(5, 0, 1))\n",
    "    hist1.fill(decisions_nn[test_y==1])    # Fills the histogram with some data\n",
    "    hist2.fill(decisions_nn[test_y ==0])\n",
    "\n",
    "    hep.histplot([hist1/hist1.size, hist2/hist2.size], label = ['signal', 'background'])\n",
    "    plt.xlabel('signal confidence')\n",
    "    plt.ylabel('Normalized Frequency')\n",
    "    plt.title(f'signal background plot')\n",
    "    plt.legend()\n",
    "    #plt.xlim(0,1)\n",
    "    plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} signal background.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [1., 2.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.empty((0,2))\n",
    "a = np.vstack((a, [1,2]))\n",
    "np.vstack((a, [1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_run(class_type, criterion, layers, hidden_dims, num_epochs):\n",
    "    model = class_type(hidden_channels=hidden_dims, num_convs=layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    test_results =  np.empty((0,2))\n",
    "    train_results =  np.empty((0,2))\n",
    "    t1 = time.perf_counter()\n",
    "    for epoch in range(num_epochs[1]):\n",
    "        model = train(model, optimizer, criterion)\n",
    "        print(f'Epoch: {epoch:03d}')\n",
    "        train_results = np.vstack((train_results, test(model, criterion, train_loader, 'train')[:-1]))\n",
    "        test_results = np.vstack((test_results, test(model, criterion, test_loader, 'test')[:-1]))\n",
    "        print()\n",
    "        if epoch>num_epochs[0]:\n",
    "            if (np.max(train_results[:,1][-5:-1]) - train_results[:,1][-1]) <0:\n",
    "                break\n",
    "    time_per_epoch = (time.perf_counter()-t1)/(epoch+1)\n",
    "    test_out = np.array([]) # first element is prediction, last element is what it should be\n",
    "    test_y = np.array([])\n",
    "    for data in test_loader:\n",
    "        x_transformed = torch.tensor(scaler.transform(data.x),dtype=torch.float32)\n",
    "        out = model(x_transformed, data.edge_index, data.batch).cpu().detach().numpy()[:,0]\n",
    "        test_out = np.hstack((test_out, out))\n",
    "        test_y = np.hstack((test_y, np.array(data.y)))\n",
    "    y_pred_test = (test_out>0.5)*1\n",
    "    \n",
    "    print(sklearn.metrics.classification_report(test_y, y_pred_test, target_names=[\"background\", \"signal\"]))\n",
    "    report = sklearn.metrics.classification_report(test_y, y_pred_test, target_names=[\"background\", \"signal\"]).split()\n",
    "    b_prec, b_recall = report[5:7]\n",
    "    s_prec, s_recall = report[10:12]\n",
    "    # save_comparison(class_type, layers, hidden_dims, train_results[-1][1], test_results[-1][1], \n",
    "    #                 train_results[-1][0], test_results[-1][0], b_prec, b_recall, s_prec, s_recall, time_per_epoch, epoch)\n",
    "    # cannot just pass in the test out since the loader is shuffled each epoch\n",
    "    plot_signal_background(test_results, train_results, test_out, test_y, class_type, layers, hidden_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- why is the test loss lower than the training (especially since the signal confidence plot is so much worse)\n",
    "    - could be due to how loss is defined - cannot be dependant on the size\n",
    "- signal rate seems to disagree wiht the visual confidence\n",
    "\n",
    "\n",
    "BEST NETWORKS\n",
    "- GCN   3 64 (>40)\n",
    "- GCN   3 128 (>40)\n",
    "- GCN   4 16 (>40)\n",
    "- GRAPH 4 8 (>40)\n",
    "- GAT   1 32 (>40) (BAD SIGANL RECALL)\n",
    "- GAT   1 64 (>40)\n",
    "- GAT   2 32 (>40)\n",
    "- GAT   3 128 (34)\n",
    "- GAT   4 128 (31) (BEST) 89, 90, 14, 13\n",
    "- GAT   5 128 (21)\n",
    "- SAGE  5 128 (21) (BEST) 89, 90, 14, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_list = [GCN, Graph, GAT, SAGE]\n",
    "# layers_list = [1,2,3,4,5]\n",
    "# hidden_dims_list = [8,16,32,64,128,256]\n",
    "class_list = [GAT]\n",
    "layers_list = [4]\n",
    "hidden_dims_list = [128]\n",
    "\n",
    "schedule = [[GAT, 4, 128], [SAGE, 5, 128]]\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.8)\n",
    "criterion = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "\n",
    "def do_it_all(class_list, layers_list, hidden_dims, num_epochs):\n",
    "    for class_type in class_list:\n",
    "        for layers in layers_list:\n",
    "            for hidden_dims in hidden_dims_list:\n",
    "                print(f'{class_type.__str__(class_type)} {layers} {hidden_dims} ')\n",
    "                each_run(class_type, criterion, layers, hidden_dims, num_epochs)\n",
    "\n",
    "def do_it_all_specific(schedule, num_epochs):\n",
    "    for process in schedule:\n",
    "        print(f'{process[0].__str__(process[0])} {process[1]} {process[2]} ')\n",
    "        each_run(process[0], criterion, process[1], process[2], num_epochs)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT 4 128 \n",
      "Epoch: 000\n",
      "train accuracy: 89.026% , loss: 1.9222, signal rate: 0.00% \n",
      "test accuracy: 88.981% , loss: 1.9289, signal rate: 0.00% \n",
      "train accuracy: 89.026% , loss: 0.3204, signal rate: 0.00% \n",
      "test accuracy: 88.981% , loss: 0.3215, signal rate: 0.00% \n",
      "\n",
      "Epoch: 001\n",
      "train accuracy: 89.026% , loss: 1.0449, signal rate: 0.00% \n",
      "test accuracy: 88.981% , loss: 1.0436, signal rate: 0.00% \n",
      "train accuracy: 89.026% , loss: 0.1741, signal rate: 0.00% \n",
      "test accuracy: 88.981% , loss: 0.1739, signal rate: 0.00% \n",
      "\n",
      "Epoch: 002\n",
      "train accuracy: 99.288% , loss: 0.2806, signal rate: 10.29% \n",
      "test accuracy: 99.311% , loss: 0.2711, signal rate: 10.41% \n",
      "train accuracy: 99.288% , loss: 0.0468, signal rate: 10.29% \n",
      "test accuracy: 99.311% , loss: 0.0452, signal rate: 10.41% \n",
      "\n",
      "Epoch: 003\n",
      "train accuracy: 99.381% , loss: 0.2350, signal rate: 10.36% \n",
      "test accuracy: 99.422% , loss: 0.2135, signal rate: 10.44% \n",
      "train accuracy: 99.381% , loss: 0.0392, signal rate: 10.36% \n",
      "test accuracy: 99.422% , loss: 0.0356, signal rate: 10.44% \n",
      "\n",
      "Epoch: 004\n",
      "train accuracy: 99.388% , loss: 0.2243, signal rate: 10.36% \n",
      "test accuracy: 99.456% , loss: 0.2026, signal rate: 10.47% \n",
      "train accuracy: 99.388% , loss: 0.0374, signal rate: 10.36% \n",
      "test accuracy: 99.456% , loss: 0.0338, signal rate: 10.47% \n",
      "\n",
      "Epoch: 005\n",
      "train accuracy: 99.394% , loss: 0.2182, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1956, signal rate: 10.50% \n",
      "train accuracy: 99.394% , loss: 0.0364, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0326, signal rate: 10.50% \n",
      "\n",
      "Epoch: 006\n",
      "train accuracy: 99.396% , loss: 0.2147, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1934, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0358, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0322, signal rate: 10.50% \n",
      "\n",
      "Epoch: 007\n",
      "train accuracy: 99.396% , loss: 0.2118, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1908, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0353, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0318, signal rate: 10.50% \n",
      "\n",
      "Epoch: 008\n",
      "train accuracy: 99.396% , loss: 0.2103, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1864, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0350, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0311, signal rate: 10.50% \n",
      "\n",
      "Epoch: 009\n",
      "train accuracy: 99.396% , loss: 0.2079, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1829, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0347, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0305, signal rate: 10.50% \n",
      "\n",
      "Epoch: 010\n",
      "train accuracy: 99.396% , loss: 0.2070, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1843, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0345, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0307, signal rate: 10.50% \n",
      "\n",
      "Epoch: 011\n",
      "train accuracy: 99.396% , loss: 0.2043, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1811, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0340, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0302, signal rate: 10.50% \n",
      "\n",
      "Epoch: 012\n",
      "train accuracy: 99.396% , loss: 0.2034, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1779, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0339, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0296, signal rate: 10.50% \n",
      "\n",
      "Epoch: 013\n",
      "train accuracy: 99.396% , loss: 0.2030, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1759, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0338, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0293, signal rate: 10.50% \n",
      "\n",
      "Epoch: 014\n",
      "train accuracy: 99.396% , loss: 0.2102, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1904, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0350, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0317, signal rate: 10.50% \n",
      "\n",
      "Epoch: 015\n",
      "train accuracy: 99.396% , loss: 0.2030, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1721, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0338, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0287, signal rate: 10.50% \n",
      "\n",
      "Epoch: 016\n",
      "train accuracy: 99.396% , loss: 0.2021, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1725, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0337, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0287, signal rate: 10.50% \n",
      "\n",
      "Epoch: 017\n",
      "train accuracy: 99.396% , loss: 0.1989, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1703, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0332, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0284, signal rate: 10.50% \n",
      "\n",
      "Epoch: 018\n",
      "train accuracy: 99.396% , loss: 0.1961, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1664, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0327, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0277, signal rate: 10.50% \n",
      "\n",
      "Epoch: 019\n",
      "train accuracy: 99.407% , loss: 0.1976, signal rate: 10.38% \n",
      "test accuracy: 99.490% , loss: 0.1750, signal rate: 10.51% \n",
      "train accuracy: 99.407% , loss: 0.0329, signal rate: 10.38% \n",
      "test accuracy: 99.490% , loss: 0.0292, signal rate: 10.51% \n",
      "\n",
      "Epoch: 020\n",
      "train accuracy: 99.396% , loss: 0.1929, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1641, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0322, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0273, signal rate: 10.50% \n",
      "\n",
      "Epoch: 021\n",
      "train accuracy: 99.403% , loss: 0.1939, signal rate: 10.38% \n",
      "test accuracy: 99.481% , loss: 0.1647, signal rate: 10.50% \n",
      "train accuracy: 99.403% , loss: 0.0323, signal rate: 10.38% \n",
      "test accuracy: 99.481% , loss: 0.0275, signal rate: 10.50% \n",
      "\n",
      "Epoch: 022\n",
      "train accuracy: 99.396% , loss: 0.1946, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.1614, signal rate: 10.50% \n",
      "train accuracy: 99.396% , loss: 0.0324, signal rate: 10.37% \n",
      "test accuracy: 99.481% , loss: 0.0269, signal rate: 10.50% \n",
      "\n",
      "Epoch: 023\n",
      "train accuracy: 99.405% , loss: 0.1894, signal rate: 10.38% \n",
      "test accuracy: 99.481% , loss: 0.1585, signal rate: 10.50% \n",
      "train accuracy: 99.405% , loss: 0.0316, signal rate: 10.38% \n",
      "test accuracy: 99.481% , loss: 0.0264, signal rate: 10.50% \n",
      "\n",
      "Epoch: 024\n",
      "train accuracy: 99.418% , loss: 0.1901, signal rate: 10.39% \n",
      "test accuracy: 99.515% , loss: 0.1672, signal rate: 10.53% \n",
      "train accuracy: 99.418% , loss: 0.0317, signal rate: 10.39% \n",
      "test accuracy: 99.515% , loss: 0.0279, signal rate: 10.53% \n",
      "\n",
      "Epoch: 025\n",
      "train accuracy: 99.411% , loss: 0.1861, signal rate: 10.39% \n",
      "test accuracy: 99.507% , loss: 0.1595, signal rate: 10.53% \n",
      "train accuracy: 99.411% , loss: 0.0310, signal rate: 10.39% \n",
      "test accuracy: 99.507% , loss: 0.0266, signal rate: 10.53% \n",
      "\n",
      "Epoch: 026\n",
      "train accuracy: 99.443% , loss: 0.1848, signal rate: 10.42% \n",
      "test accuracy: 99.532% , loss: 0.1611, signal rate: 10.55% \n",
      "train accuracy: 99.443% , loss: 0.0308, signal rate: 10.42% \n",
      "test accuracy: 99.532% , loss: 0.0269, signal rate: 10.55% \n",
      "\n",
      "Epoch: 027\n",
      "train accuracy: 99.428% , loss: 0.1787, signal rate: 10.40% \n",
      "test accuracy: 99.524% , loss: 0.1432, signal rate: 10.54% \n",
      "train accuracy: 99.428% , loss: 0.0298, signal rate: 10.40% \n",
      "test accuracy: 99.524% , loss: 0.0239, signal rate: 10.54% \n",
      "\n",
      "Epoch: 028\n",
      "train accuracy: 99.430% , loss: 0.1807, signal rate: 10.40% \n",
      "test accuracy: 99.524% , loss: 0.1427, signal rate: 10.54% \n",
      "train accuracy: 99.430% , loss: 0.0301, signal rate: 10.40% \n",
      "test accuracy: 99.524% , loss: 0.0238, signal rate: 10.54% \n",
      "\n",
      "Epoch: 029\n",
      "train accuracy: 99.462% , loss: 0.1695, signal rate: 10.44% \n",
      "test accuracy: 99.541% , loss: 0.1408, signal rate: 10.56% \n",
      "train accuracy: 99.462% , loss: 0.0283, signal rate: 10.44% \n",
      "test accuracy: 99.541% , loss: 0.0235, signal rate: 10.56% \n",
      "\n",
      "Epoch: 030\n",
      "train accuracy: 99.462% , loss: 0.1707, signal rate: 10.44% \n",
      "test accuracy: 99.549% , loss: 0.1452, signal rate: 10.57% \n",
      "train accuracy: 99.462% , loss: 0.0284, signal rate: 10.44% \n",
      "test accuracy: 99.549% , loss: 0.0242, signal rate: 10.57% \n",
      "\n",
      "Epoch: 031\n",
      "train accuracy: 99.471% , loss: 0.1748, signal rate: 10.45% \n",
      "test accuracy: 99.566% , loss: 0.1484, signal rate: 10.58% \n",
      "train accuracy: 99.471% , loss: 0.0291, signal rate: 10.45% \n",
      "test accuracy: 99.566% , loss: 0.0247, signal rate: 10.58% \n",
      "\n",
      "Epoch: 032\n",
      "train accuracy: 99.469% , loss: 0.1606, signal rate: 10.45% \n",
      "test accuracy: 99.566% , loss: 0.1285, signal rate: 10.58% \n",
      "train accuracy: 99.469% , loss: 0.0268, signal rate: 10.45% \n",
      "test accuracy: 99.566% , loss: 0.0214, signal rate: 10.58% \n",
      "\n",
      "Epoch: 033\n",
      "train accuracy: 99.477% , loss: 0.1591, signal rate: 10.46% \n",
      "test accuracy: 99.566% , loss: 0.1294, signal rate: 10.58% \n",
      "train accuracy: 99.477% , loss: 0.0265, signal rate: 10.46% \n",
      "test accuracy: 99.566% , loss: 0.0216, signal rate: 10.58% \n",
      "\n",
      "Epoch: 034\n",
      "train accuracy: 99.483% , loss: 0.1534, signal rate: 10.46% \n",
      "test accuracy: 99.566% , loss: 0.1145, signal rate: 10.60% \n",
      "train accuracy: 99.483% , loss: 0.0256, signal rate: 10.46% \n",
      "test accuracy: 99.566% , loss: 0.0191, signal rate: 10.60% \n",
      "\n",
      "Epoch: 035\n",
      "train accuracy: 99.515% , loss: 0.1580, signal rate: 10.50% \n",
      "test accuracy: 99.626% , loss: 0.1245, signal rate: 10.66% \n",
      "train accuracy: 99.515% , loss: 0.0263, signal rate: 10.50% \n",
      "test accuracy: 99.626% , loss: 0.0208, signal rate: 10.66% \n",
      "\n",
      "Epoch: 036\n",
      "train accuracy: 99.520% , loss: 0.1492, signal rate: 10.50% \n",
      "test accuracy: 99.634% , loss: 0.1090, signal rate: 10.69% \n",
      "train accuracy: 99.520% , loss: 0.0249, signal rate: 10.50% \n",
      "test accuracy: 99.634% , loss: 0.0182, signal rate: 10.69% \n",
      "\n",
      "Epoch: 037\n",
      "train accuracy: 99.545% , loss: 0.1478, signal rate: 10.53% \n",
      "test accuracy: 99.668% , loss: 0.1158, signal rate: 10.72% \n",
      "train accuracy: 99.545% , loss: 0.0246, signal rate: 10.53% \n",
      "test accuracy: 99.668% , loss: 0.0193, signal rate: 10.72% \n",
      "\n",
      "Epoch: 038\n",
      "train accuracy: 99.543% , loss: 0.1447, signal rate: 10.53% \n",
      "test accuracy: 99.660% , loss: 0.1086, signal rate: 10.71% \n",
      "train accuracy: 99.543% , loss: 0.0241, signal rate: 10.53% \n",
      "test accuracy: 99.660% , loss: 0.0181, signal rate: 10.71% \n",
      "\n",
      "Epoch: 039\n",
      "train accuracy: 99.545% , loss: 0.1448, signal rate: 10.53% \n",
      "test accuracy: 99.668% , loss: 0.1139, signal rate: 10.72% \n",
      "train accuracy: 99.545% , loss: 0.0241, signal rate: 10.53% \n",
      "test accuracy: 99.668% , loss: 0.0190, signal rate: 10.72% \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       1.00      1.00      1.00     10466\n",
      "      signal       1.00      0.97      0.98      1296\n",
      "\n",
      "    accuracy                           1.00     11762\n",
      "   macro avg       1.00      0.99      0.99     11762\n",
      "weighted avg       1.00      1.00      1.00     11762\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/GAT, layers 4, dims 128 ROC plot.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdo_it_all_specific\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 24\u001b[0m, in \u001b[0;36mdo_it_all_specific\u001b[1;34m(schedule, num_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m schedule:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m(process[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     \u001b[43meach_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 35\u001b[0m, in \u001b[0;36meach_run\u001b[1;34m(class_type, criterion, layers, hidden_dims, num_epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m s_prec, s_recall \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m12\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# save_comparison(class_type, layers, hidden_dims, train_results[-1][1], test_results[-1][1], \u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#                 train_results[-1][0], test_results[-1][0], b_prec, b_recall, s_prec, s_recall, time_per_epoch, epoch)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# cannot just pass in the test out since the loader is shuffled each epoch\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mplot_signal_background\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 14\u001b[0m, in \u001b[0;36mplot_signal_background\u001b[1;34m(test_results, train_results, decisions_nn, test_y, class_type, layers, hidden_dims)\u001b[0m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()  \u001b[38;5;66;03m# add a grid to the plot\u001b[39;00m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()  \u001b[38;5;66;03m# add a legend\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplots/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclass_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, layers \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayers\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, dims \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhidden_dims\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m ROC plot.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(train_results)), train_results[:,\u001b[38;5;241m1\u001b[39m],linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m,  label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\figure.py:3343\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3339\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3340\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[0;32m   3341\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m-> 3343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2428\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2428\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2431\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/GAT, layers 4, dims 128 ROC plot.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_it_all_specific(schedule, (20,40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
