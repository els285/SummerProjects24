{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot \n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "import torch\n",
    "import torch_hep\n",
    "import torch_geometric\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/HP/Documents/data/'\n",
    "base =  uproot.open(path+\"4top_parton_CPstudy.root\") \n",
    "tree_even = base['CP_even']\n",
    "tree_odd = base['CP_odd']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic_even = {}\n",
    "dic_even['pt'] = np.hstack((tree_even['t_pt'].array(), tree_even['tbar_pt'].array()))\n",
    "length_even = len(dic_even['pt'])\n",
    "dic_even['eta'] = np.hstack((tree_even['t_eta'].array(), tree_even['tbar_eta'].array()))\n",
    "dic_even['phi'] = np.hstack((tree_even['t_phi'].array(), tree_even['tbar_phi'].array()))\n",
    "dic_even['e'] = np.hstack((tree_even['t_e'].array(), tree_even['tbar_e'].array()))\n",
    "dic_even['type'] = np.hstack((np.zeros((length_even,2)), np.ones((length_even,2))))\n",
    "\n",
    "\n",
    "dic_odd = {}\n",
    "dic_odd['pt'] = np.hstack((tree_odd['t_pt'].array(), tree_odd['tbar_pt'].array()))\n",
    "length_odd = len(dic_odd['pt'])\n",
    "dic_odd['eta'] = np.hstack((tree_odd['t_eta'].array(), tree_odd['tbar_eta'].array()))\n",
    "dic_odd['phi'] = np.hstack((tree_odd['t_phi'].array(), tree_odd['tbar_phi'].array()))\n",
    "dic_odd['e'] = np.hstack((tree_odd['t_e'].array(), tree_odd['tbar_e'].array()))\n",
    "dic_odd['type'] = np.hstack((np.zeros((length_odd,2)), np.ones((length_odd,2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600000/600000 [02:26<00:00, 4104.26it/s]\n",
      "100%|██████████| 600000/600000 [02:33<00:00, 3910.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for i in tqdm(range(length_odd)):\n",
    "    G = torch_hep.graph.GraphBuilder()\n",
    "    G.add_asNode(key='x', pt = dic_odd['pt'][i], eta = dic_odd['eta'][i], phi = dic_odd['phi'][i], e = dic_odd['e'][i], type = dic_odd['type'][i],dtype=torch.float32)\n",
    "    G.add_asEdge(key='edge_attrs', index=list(itertools.permutations(range(len(dic_odd['pt'][i])),2)), dtype=torch.int64)\n",
    "    G.add_asGlobal(key='y', IsSIG=1, dtype=torch.float32)\n",
    "    # G.add_asGlobal(key='w', weight=1, dtype=torch.float32)\n",
    "\n",
    "    dataset.append(G.to_Data())\n",
    "\n",
    "for i in tqdm(range(length_even)):\n",
    "    G = torch_hep.graph.GraphBuilder()\n",
    "    G.add_asNode(key='x', pt = dic_even['pt'][i] ,eta = dic_even['eta'][i], phi = dic_even['phi'][i] , e = dic_even['e'][i], type = dic_even['type'][i],dtype=torch.float32)\n",
    "    G.add_asEdge(key='edge_attrs', index=list(itertools.permutations(range(len(dic_even['pt'][i])),2)), dtype=torch.int64)\n",
    "    G.add_asGlobal(key='y', IsSIG=0, dtype=torch.float32)\n",
    "    # G.add_asGlobal(key='w', weight=0.12, dtype=torch.float32)\n",
    "\n",
    "    dataset.append(G.to_Data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 960000\n",
      "Number of test graphs: 240000\n",
      "percentage of graphs that are signal: 50.00%\n"
     ]
    }
   ],
   "source": [
    "seed = 141592\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(dataset)\n",
    "#size = 200000\n",
    "size = len(dataset)\n",
    "cutoff = int(size*0.8)\n",
    "#cutoff = 1000\n",
    "\n",
    "train_dataset = dataset[:cutoff]\n",
    "test_dataset = dataset[cutoff:size]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "print(f'percentage of graphs that are signal: {100* length_odd/(length_odd + length_even):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "scaler_loader = [i for i in DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)][0]\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(scaler_loader.x)\n",
    "#total_loader = [i for i in DataLoader(dataset, batch_size=len(dataset), shuffle=True)][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(GCNConv(5, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'GCN'\n",
    "    \n",
    "class Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(Graph, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(GraphConv(5, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(GraphConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'GRAPH'\n",
    "    #GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(GAT, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(GATConv(5, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(GATConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'GAT'\n",
    "    \n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_convs):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.convs = nn.ModuleList()  # Use ModuleList to store layers\n",
    "        self.convs.append(SAGEConv(5, hidden_channels))\n",
    "        for _ in range(num_convs - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, 1)  # Linear layer for final output\n",
    "        # GraphConv\n",
    "        # GCNConv\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.01, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return torch.nn.functional.sigmoid(x)\n",
    "    def __str__(self):\n",
    "        return 'SAGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(out_numpy, all_y, zoomed = False):\n",
    "    hep.style.use(hep.style.ATLAS)\n",
    "    if zoomed:\n",
    "        hist1 = bh.Histogram(bh.axis.Regular(50, 0.98, 1)) # Initialises empty histogram with 50 bins spanning [0,500]\n",
    "        hist2 = bh.Histogram(bh.axis.Regular(50, 0.98, 1))\n",
    "    else:\n",
    "        hist1 = bh.Histogram(bh.axis.Regular(5, 0, 1)) # Initialises empty histogram with 50 bins spanning [0,500]\n",
    "        hist2 = bh.Histogram(bh.axis.Regular(5, 0, 1))\n",
    "    hist1.fill(out_numpy[all_y==1])    # Fills the histogram with some data\n",
    "    hist2.fill(out_numpy[all_y ==0])\n",
    "\n",
    "\n",
    "    hep.histplot([hist1/hist1.size, hist2/hist2.size], label = ['signal', 'background'])\n",
    "    plt.xlabel('signal confidence')\n",
    "    plt.ylabel('Normalized Frequency')\n",
    "    plt.title(f'signal background plot')\n",
    "    plt.legend()\n",
    "    #plt.xlim(0,1)\n",
    "    #plt.savefig(f'using_adam_images\\{dim} signal background zoomed.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import BinaryAccuracy\n",
    "def train_test(model, optimizer, criterion, loader, output = ''):\n",
    "    if output == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    total_loss = 0\n",
    "    metric = BinaryAccuracy()\n",
    "    #out_numpy = np.array([])\n",
    "    for data in loader:  # Iterate in batches over the training dataset. \n",
    "        x_transformed = torch.tensor(scaler.transform(data.x),dtype=torch.float32)\n",
    "        out = model(x_transformed, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        metric.update(out.flatten(), data.y)\n",
    "        # loss = torch.sum(criterion(out, data.y.reshape(-1,1))*data.w.reshape(-1,1)) / data.w.sum()# Compute the loss.\n",
    "        loss = criterion(out, data.y.reshape(-1,1))\n",
    "        if output == 'train':\n",
    "            optimizer.zero_grad()  # Clear gradients.   \n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        total_loss += loss.item() * data.size(0)\n",
    "    total_loss /= len(loader.dataset)\n",
    "    accuracy = metric.compute().item()\n",
    "    if output:\n",
    "        print(f'{output} accuracy: {100*accuracy:.3f}% , loss: {total_loss:.6f}')\n",
    "    return model, accuracy, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_comparison(class_type, layers, hidden_dims, train_loss, test_loss, train_acc, test_acc, b_prec, b_recall, s_prec, s_recall, training_time, epoch, learn_rate):\n",
    "    file_path = 'performance_comparison.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        print('hi')\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        print('by')\n",
    "\n",
    "\n",
    "    # Data to append\n",
    "    data_to_append = {\n",
    "        'class type': [class_type.__str__(class_type)],\n",
    "        'layers': [layers],\n",
    "        'hidden_dims': [hidden_dims],\n",
    "        'learn_rate': [learn_rate],\n",
    "        'training loss' : [train_loss],\n",
    "        'training accuracy' : [train_acc],\n",
    "        'test cost' : [test_loss],\n",
    "        'training accuracy': [train_acc],\n",
    "        'test accuracy': [test_acc],\n",
    "        'training time': [training_time],\n",
    "        'background precision': [b_prec],\n",
    "        'background recall': [b_recall],\n",
    "        'signal precision': [s_prec],\n",
    "        'signal recall': [s_recall],\n",
    "        'training time per epoch' : [training_time],\n",
    "        'epochs':[epoch+1]\n",
    "    }\n",
    "\n",
    "    df_to_append = pd.DataFrame(data_to_append)\n",
    "    df = df.dropna(how='all', axis=1)\n",
    "    df_to_append = df_to_append.dropna(how='all', axis=1)\n",
    "\n",
    "    # Concatenate the existing DataFrame with the new data\n",
    "    df = pd.concat([df, df_to_append], ignore_index=True)\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each epoch:\n",
    "train accuracy, train loss, train signal rate\n",
    "test accuracy, test loss, test signal rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN\n",
    "------------\n",
    "- move graphs onto this program\n",
    "    - roc, accuracy over epochs, cost over epochs\n",
    "\n",
    "- move the array of cost an accuracy to the initialisation of the model, so it keeps all the training data\n",
    "- write a general function ot test different numbers of hidden layers, plot results, save results to an excel\n",
    "- try all above for cp odd and cp even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_background(test_results, train_results, decisions_nn, test_y, class_type, layers, hidden_dims, learn_rate, save=False):\n",
    "    fpr_nn, tpr_nn, thresholds_nn = sklearn.metrics.roc_curve(test_y, decisions_nn)\n",
    "    # may need decisions to be 2 dimensional\n",
    "    class_str = class_type.__str__(class_type)\n",
    "\n",
    "    plt.plot(fpr_nn, tpr_nn, linestyle=\"dashed\", label=\"Neural Network\")  # plot neural network ROC\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"dotted\", color=\"grey\", label=\"Luck\")  # plot diagonal line to indicate luck\n",
    "    plt.xlabel(\"False Positive Rate\")  # x-axis label\n",
    "    plt.ylabel(\"True Positive Rate\")  # y-axis label\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(f'{class_str}, layers {layers}, dims {hidden_dims} {learn_rate} ROC plot')\n",
    "    plt.grid()  # add a grid to the plot\n",
    "    plt.legend()  # add a legend\n",
    "    if save:\n",
    "        plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} {learn_rate} ROC plot.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(np.arange(len(train_results)), train_results[:,1],linestyle='-', marker='o',  label = 'train loss')\n",
    "    plt.plot(np.arange(len(test_results)), test_results[:,1], linestyle='-', marker='o', label = 'test loss')\n",
    "    plt.xlabel(\"Epochs\")  # x-axis label\n",
    "    plt.ylabel(\"Loss\")  # y-axis label\n",
    "    plt.title(f'Loss at each Epoch {class_str}, layers {layers}, dims {hidden_dims} {learn_rate}')\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} {learn_rate} loss at each epoch.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(len(train_results)), train_results[:,0],linestyle='-', marker='o',  label = 'train accuracy')\n",
    "    plt.plot(np.arange(len(test_results)), test_results[:,0], linestyle='-', marker='o', label = 'test accuracy')\n",
    "    plt.xlabel(\"Epochs\")  # x-axis label\n",
    "    plt.ylabel(\"Percentage Accuracy\")  # y-axis label\n",
    "    plt.title(f'Accuracy {class_str}, layers {layers}, dims {hidden_dims} {learn_rate}')\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} {learn_rate} accuracy at each epoch.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    hep.style.use(hep.style.ATLAS)\n",
    "\n",
    "    hist1 = bh.Histogram(bh.axis.Regular(70, 0.3, 0.7)) # Initialises empty histogram with 50 bins spanning [0,500]\n",
    "    hist2 = bh.Histogram(bh.axis.Regular(70, 0.3, 0.7))\n",
    "    hist1.fill(decisions_nn[test_y==1])    # Fills the histogram with some data\n",
    "    hist2.fill(decisions_nn[test_y ==0])\n",
    "\n",
    "    hep.histplot([hist1/hist1.size, hist2/hist2.size], label = ['signal', 'background'])\n",
    "    plt.xlabel('signal confidence')\n",
    "    plt.ylabel('Normalized Frequency')\n",
    "    plt.title(f'signal background plot {class_str}, layers {layers}, dims {hidden_dims} {learn_rate}')\n",
    "    plt.legend()\n",
    "    #plt.xlim(0,1)\n",
    "    if save:\n",
    "        plt.savefig(f'plots/{class_str}, layers {layers}, dims {hidden_dims} {learn_rate} signal background.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_run(class_type, criterion, layers, hidden_dims, learn_rate, num_epochs):\n",
    "    model = class_type(hidden_channels=hidden_dims, num_convs=layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    test_results =  np.empty((0,2))\n",
    "    train_results =  np.empty((0,2))\n",
    "    t1 = time.perf_counter()\n",
    "    for epoch in range(num_epochs[1]):\n",
    "        print(f'Epoch: {epoch:03d}')\n",
    "        model, acc, loss = train_test(model, optimizer, criterion, train_loader, 'train')\n",
    "        train_results = np.vstack((train_results, [acc,loss]))\n",
    "        model, acc, loss = train_test(model, optimizer, criterion, test_loader, 'test')\n",
    "        test_results = np.vstack((test_results, [acc,loss]))\n",
    "        print()\n",
    "        if epoch>num_epochs[0]:\n",
    "            if (np.max(train_results[:,1][-5:-1]) - train_results[:,1][-1]) <0:\n",
    "                break\n",
    "    time_per_epoch = (time.perf_counter()-t1)/(epoch+1)\n",
    "    test_out = np.array([]) # first element is prediction, last element is what it should be\n",
    "    test_y = np.array([])\n",
    "    for data in test_loader:\n",
    "        x_transformed = torch.tensor(scaler.transform(data.x),dtype=torch.float32)\n",
    "        out = model(x_transformed, data.edge_index, data.batch).cpu().detach().numpy()[:,0]\n",
    "        test_out = np.hstack((test_out, out))\n",
    "        test_y = np.hstack((test_y, np.array(data.y)))\n",
    "    y_pred_test = (test_out>0.5)*1\n",
    "    \n",
    "    print(sklearn.metrics.classification_report(test_y, y_pred_test, target_names=[\"background\", \"signal\"]))\n",
    "    report = sklearn.metrics.classification_report(test_y, y_pred_test, target_names=[\"background\", \"signal\"]).split()\n",
    "    b_prec, b_recall = report[5:7]\n",
    "    s_prec, s_recall = report[10:12]\n",
    "    save_comparison(class_type, layers, hidden_dims, train_results[-1][1], test_results[-1][1], \n",
    "                    train_results[-1][0], test_results[-1][0], b_prec, b_recall, s_prec, s_recall, time_per_epoch, epoch, learn_rate)\n",
    "    # cannot just pass in the test out since the loader is shuffled each epoch\n",
    "    plot_signal_background(test_results, train_results, test_out, test_y, class_type, layers, hidden_dims, learn_rate, save = True)\n",
    "    torch.save(model.state_dict(), f'models\\model {class_type.__str__(class_type)} {layers} {hidden_dims} {epoch+1} {0.001}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- why is the test loss lower than the training (especially since the signal confidence plot is so much worse)\n",
    "    - could be due to how loss is defined - cannot be dependant on the size\n",
    "- signal rate seems to disagree wiht the visual confidence\n",
    "\n",
    "\n",
    "BEST NETWORKS\n",
    "- GCN   3 64 (>40)\n",
    "- GCN   3 128 (>40)\n",
    "- GCN   4 16 (>40)\n",
    "- GRAPH 4 8 (>40)\n",
    "- GAT   1 32 (>40) (BAD SIGANL RECALL)\n",
    "- GAT   1 64 (>40)\n",
    "- GAT   2 32 (>40)\n",
    "- GAT   3 128 (34)\n",
    "- GAT   4 128 (31) (BEST) 89, 90, 14, 13\n",
    "- GAT   5 128 (21)\n",
    "- SAGE  5 128 (21) (BEST) 89, 90, 14, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_list = [GCN, Graph, GAT, SAGE]\n",
    "# layers_list = [1,2,3,4,5]\n",
    "# hidden_dims_list = [8,16,32,64,128,256]\n",
    "# class_list = [SAGE]\n",
    "# layers_list = [4]\n",
    "# hidden_dims_list = [64]\n",
    "\n",
    "schedule = [[SAGE, 4, 64, 0.0001], [SAGE, 4, 64, 0.001]]\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.8)\n",
    "criterion = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "\n",
    "def do_it_all(class_list, layers_list, hidden_dims_list, num_epochs, learn_rate):\n",
    "    for class_type in class_list:\n",
    "        for layers in layers_list:\n",
    "            for hidden_dims in hidden_dims_list:\n",
    "                print(f'{class_type.__str__(class_type)} {layers} {hidden_dims} {learn_rate} ')\n",
    "                each_run(class_type, criterion, layers, hidden_dims, learn_rate, num_epochs)\n",
    "\n",
    "def do_it_all_specific(schedule, num_epochs):\n",
    "    for process in schedule:\n",
    "        print(f'{process[0].__str__(process[0])} {process[1]} {process[2]} {process[3]} ')\n",
    "        each_run(process[0], criterion, process[1], process[2], process[3], num_epochs)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGE 4 64 0.0001 \n",
      "train accuracy: 52.818% , loss: 2.763606\n",
      "test accuracy: 52.967% , loss: 2.762600\n",
      "\n",
      "train accuracy: 52.984% , loss: 2.762345\n",
      "test accuracy: 52.840% , loss: 2.763462\n",
      "\n",
      "train accuracy: 53.145% , loss: 2.761030\n",
      "test accuracy: 53.053% , loss: 2.761122\n",
      "\n",
      "train accuracy: 53.277% , loss: 2.759714\n",
      "test accuracy: 53.477% , loss: 2.758525\n",
      "\n",
      "train accuracy: 53.422% , loss: 2.758678\n",
      "test accuracy: 53.474% , loss: 2.757629\n",
      "\n",
      "train accuracy: 53.502% , loss: 2.758109\n",
      "test accuracy: 53.605% , loss: 2.757202\n",
      "\n",
      "train accuracy: 53.587% , loss: 2.757562\n",
      "test accuracy: 53.580% , loss: 2.756406\n",
      "\n",
      "train accuracy: 53.599% , loss: 2.756961\n",
      "test accuracy: 53.612% , loss: 2.756264\n",
      "\n",
      "train accuracy: 53.695% , loss: 2.756386\n",
      "test accuracy: 53.579% , loss: 2.757168\n",
      "\n",
      "train accuracy: 53.714% , loss: 2.755948\n",
      "test accuracy: 53.609% , loss: 2.756563\n",
      "\n",
      "train accuracy: 53.789% , loss: 2.755411\n",
      "test accuracy: 53.773% , loss: 2.754980\n",
      "\n",
      "train accuracy: 53.843% , loss: 2.754902\n",
      "test accuracy: 53.809% , loss: 2.754792\n",
      "\n",
      "train accuracy: 53.848% , loss: 2.754558\n",
      "test accuracy: 53.742% , loss: 2.755133\n",
      "\n",
      "train accuracy: 53.919% , loss: 2.754040\n",
      "test accuracy: 53.741% , loss: 2.755912\n",
      "\n",
      "train accuracy: 53.950% , loss: 2.753440\n",
      "test accuracy: 53.810% , loss: 2.755320\n",
      "\n",
      "train accuracy: 53.999% , loss: 2.753113\n",
      "test accuracy: 53.757% , loss: 2.756417\n",
      "\n",
      "train accuracy: 54.016% , loss: 2.752734\n",
      "test accuracy: 53.850% , loss: 2.755073\n",
      "\n",
      "train accuracy: 54.083% , loss: 2.752234\n",
      "test accuracy: 53.750% , loss: 2.755882\n",
      "\n",
      "train accuracy: 54.179% , loss: 2.751815\n",
      "test accuracy: 53.914% , loss: 2.754386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_it_all_specific(schedule, (25,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = SAGE\n",
    "layers = 4\n",
    "hidden_dims = 64\n",
    "\n",
    "\n",
    "model = class_type(hidden_channels=hidden_dims, num_convs =layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.8)\n",
    "criterion = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "\n",
    "test_results =  np.empty((0,2))\n",
    "train_results =  np.empty((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in tqdm(range(30)):\n",
    "    print(f'Epoch: {epoch:03d}')\n",
    "    train_results = np.vstack((train_results, train_test(train_loader,scaler, 'train')))\n",
    "    test_results = np.vstack((test_results, train_test(test_loader,scaler, 'test')))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = np.array([]) # first element is prediction, last element is what it should be\n",
    "test_y = np.array([])\n",
    "x_transformed = torch.tensor(scaler.transform(data.x),dtype=torch.float32)\n",
    "out = model(x_transformed, data.edge_index, data.batch).cpu().detach().numpy()[:,0]\n",
    "test_out = np.hstack((test_out, out))\n",
    "test_y = np.hstack((test_y, np.array(data.y)))\n",
    "y_pred_test = (test_out>0.5)*1\n",
    "\n",
    "print(sklearn.metrics.classification_report(test_y, y_pred_test, target_names=[\"background\", \"signal\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal_background(test_results, train_results, test_out, test_y, class_type, layers, hidden_dims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
